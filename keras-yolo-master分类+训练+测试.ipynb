{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train and val size: 89\n",
      "train size: 71\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    " \n",
    "if len(sys.argv) < 2:\n",
    "    print(\"no directory specified, please input target directory\")\n",
    "    exit()\n",
    " \n",
    "root_path = sys.argv[1]\n",
    " \n",
    "xmlfilepath = 'D:/workflow/keras-yolo3-master/VOCdevkit/VOC2007/Annotations'\n",
    "txtsavepath = 'D:/workflow/keras-yolo3-master/VOCdevkit/VOC2007/ImageSets/Main'\n",
    " \n",
    "if not os.path.exists(root_path):\n",
    "    print(\"cannot find such directory: \" + root_path)\n",
    "    exit()\n",
    " \n",
    "if not os.path.exists(txtsavepath):\n",
    "    os.makedirs(txtsavepath)\n",
    " \n",
    "trainval_percent = 0.9\n",
    "train_percent = 0.8\n",
    "total_xml = os.listdir(xmlfilepath)\n",
    "num = len(total_xml)\n",
    "list = range(num)\n",
    "tv = int(num * trainval_percent)\n",
    "tr = int(tv * train_percent)\n",
    "trainval = random.sample(list, tv)\n",
    "train = random.sample(trainval, tr)\n",
    " \n",
    "print(\"train and val size:\", tv)\n",
    "print(\"train size:\", tr)\n",
    " \n",
    "ftrainval = open(txtsavepath + '/trainval.txt', 'w')\n",
    "ftest = open(txtsavepath + '/test.txt', 'w')\n",
    "ftrain = open(txtsavepath + '/train.txt', 'w')\n",
    "fval = open(txtsavepath + '/val.txt', 'w')\n",
    " \n",
    "for i in list:\n",
    "    name = total_xml[i][:-4] + '\\n'\n",
    "    if i in trainval:\n",
    "        ftrainval.write(name)\n",
    "        if i in train:\n",
    "            ftrain.write(name)\n",
    "        else:\n",
    "            fval.write(name)\n",
    "    else:\n",
    "        ftest.write(name)\n",
    " \n",
    "ftrainval.close()\n",
    "ftrain.close()\n",
    "fval.close()\n",
    "ftest.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "   annotation_path = '2007_train.txt'\n",
    "   log_dir = 'logs/000/'\n",
    "   classes_path = 'model_data/voc_classes.txt'\n",
    "   anchors_path = 'model_data/yolo_anchors.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create YOLOv3 model with 9 anchors and 1 classes.\n",
      "Train on 64 samples, val on 7 samples, with batch size 2.\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 43s 1s/step - loss: 2243.6259 - val_loss: 111958319.3438\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 22s 688ms/step - loss: 284.2927 - val_loss: 78788.8672\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 22s 688ms/step - loss: 180.0506 - val_loss: 362194.9848\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 22s 689ms/step - loss: 162.8722 - val_loss: 281.9111\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 22s 689ms/step - loss: 118.2100 - val_loss: 344.8392\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 22s 688ms/step - loss: 96.4972 - val_loss: 115.6825\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 22s 689ms/step - loss: 83.9033 - val_loss: 92.9861\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 22s 689ms/step - loss: 77.9453 - val_loss: 81.6338\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 22s 690ms/step - loss: 70.6879 - val_loss: 73.2136\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 22s 690ms/step - loss: 70.3409 - val_loss: 77.4043\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 22s 690ms/step - loss: 67.8573 - val_loss: 76.2167\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 22s 690ms/step - loss: 68.7906 - val_loss: 71.5545\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 22s 690ms/step - loss: 67.1686 - val_loss: 2518.4585\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 22s 690ms/step - loss: 69.8671 - val_loss: 80.3848\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 65.5039 - val_loss: 4062.9973\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 63.3759 - val_loss: 331.3432\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 72.2267 - val_loss: 66.0624\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 64.4052 - val_loss: 60.5282\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 22s 690ms/step - loss: 61.6145 - val_loss: 63.1798\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 22s 690ms/step - loss: 60.9542 - val_loss: 65.6321\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 59.2010 - val_loss: 62.4343\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 59.0278 - val_loss: 54.3119\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 58.8841 - val_loss: 73.5512\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 57.3147 - val_loss: 54.0210\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 58.2221 - val_loss: 58.6787\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 57.6658 - val_loss: 59.4415\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 22s 690ms/step - loss: 57.9044 - val_loss: 135.5457\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 54.6382 - val_loss: 220.9874\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 57.6523 - val_loss: 70.3204\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 61.4883 - val_loss: 56.8112\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 78.1226 - val_loss: 730669.0432\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 64.8470 - val_loss: 60.7083\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 76.3670 - val_loss: 744925.1876\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 73.4105 - val_loss: 89350.2659\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 65.4356 - val_loss: 20047.0913\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 64.2145 - val_loss: 33532.0658\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 22s 692ms/step - loss: 63.2887 - val_loss: 206.6881\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 22s 692ms/step - loss: 60.9212 - val_loss: 150.4262\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 58.1488 - val_loss: 53.7412\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 22s 692ms/step - loss: 58.8647 - val_loss: 62.0593\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 58.1709 - val_loss: 77.0109\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 59.8164 - val_loss: 62.7079\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 57.9438 - val_loss: 49.0776\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 55.4836 - val_loss: 44.8869\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 56.2003 - val_loss: 54.2839\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 57.3179 - val_loss: 55.3309\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 55.9026 - val_loss: 53.8182\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 22s 692ms/step - loss: 55.7447 - val_loss: 62.1887\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 22s 690ms/step - loss: 54.0633 - val_loss: 55.8183\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 53.4498 - val_loss: 58.5458\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 54.6769 - val_loss: 49.0596\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 53.5207 - val_loss: 51.2326\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 52.8417 - val_loss: 52.2738\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 49.2748 - val_loss: 47.5531\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 22s 690ms/step - loss: 51.2796 - val_loss: 55.9462\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 48.7613 - val_loss: 47.2600\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 50.6468 - val_loss: 44.4363\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 49.7930 - val_loss: 44.6489\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 49.0812 - val_loss: 52.6134\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 49.6940 - val_loss: 42.9093\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 48.6576 - val_loss: 57.8670\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 22s 690ms/step - loss: 49.2851 - val_loss: 62.6063\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 52.8840 - val_loss: 49.1357\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 48.7091 - val_loss: 52.3951\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 50.7355 - val_loss: 48.0612\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 49.3304 - val_loss: 53.5577\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 48.9783 - val_loss: 44.5828\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 49.8716 - val_loss: 51.6251\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 48.1763 - val_loss: 48.1034\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 47.1756 - val_loss: 43.5000\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 47.8180 - val_loss: 48.0482\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 47.5107 - val_loss: 46.8377\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 22s 692ms/step - loss: 48.5713 - val_loss: 47.4561\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 48.2101 - val_loss: 48.8532\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 47.0955 - val_loss: 50.3004\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 46.3931 - val_loss: 52.9372\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 44.6942 - val_loss: 50.1994\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 45.9845 - val_loss: 43.1612\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 45.5492 - val_loss: 42.7108\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 45.7135 - val_loss: 47.1295\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 45.6655 - val_loss: 43.8144\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 44.5633 - val_loss: 49.8953\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 42.8947 - val_loss: 51.6518\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 42.9855 - val_loss: 49.4450\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 43.8927 - val_loss: 41.1722\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 45.5759 - val_loss: 43.8038\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 22s 690ms/step - loss: 45.1217 - val_loss: 42.2033\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 43.7082 - val_loss: 43.4994\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 43.9652 - val_loss: 45.3204\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 42.6717 - val_loss: 45.5503\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 43.4154 - val_loss: 45.4228\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 43.0622 - val_loss: 41.4259\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 42.6453 - val_loss: 42.5073\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 44.2030 - val_loss: 35.4743\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 22s 690ms/step - loss: 43.0534 - val_loss: 40.5778\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 42.5903 - val_loss: 43.7134\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 42.7835 - val_loss: 46.1633\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 43.1953 - val_loss: 49.4593\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 22s 692ms/step - loss: 42.6607 - val_loss: 43.9991\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 43.0588 - val_loss: 39.7780\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 43.0101 - val_loss: 38.1341\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 41.1579 - val_loss: 44.1470\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 41.1939 - val_loss: 52.6276\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 41.6915 - val_loss: 49.3160\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 41.0759 - val_loss: 46.8155\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 42.3173 - val_loss: 43.1226\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 41.0350 - val_loss: 41.4157\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 22s 690ms/step - loss: 41.5231 - val_loss: 45.7729\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 41.8833 - val_loss: 37.8891\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 42.5297 - val_loss: 45.4258\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 41.2925 - val_loss: 40.1484\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 39.6920 - val_loss: 43.4231\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 22s 692ms/step - loss: 40.9338 - val_loss: 37.4497\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 40.3072 - val_loss: 41.7156\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 41.9077 - val_loss: 42.2667\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 40.4538 - val_loss: 37.4430\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 39.9659 - val_loss: 45.8748\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 22s 692ms/step - loss: 39.4767 - val_loss: 41.3009\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 38.0676 - val_loss: 44.6724\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 22s 692ms/step - loss: 41.1072 - val_loss: 39.2971\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 39.5635 - val_loss: 42.3323\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 39.8726 - val_loss: 46.6415\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 39.6422 - val_loss: 36.1062\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 39.3831 - val_loss: 39.2856\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 38.0559 - val_loss: 44.4124\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 39.2937 - val_loss: 45.7274\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 39.9183 - val_loss: 42.3083\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 22s 690ms/step - loss: 38.9870 - val_loss: 47.5826\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 38.4860 - val_loss: 44.8288\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 39.3292 - val_loss: 38.2775\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 38.8578 - val_loss: 43.5128\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 22s 690ms/step - loss: 38.8706 - val_loss: 45.2390\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 38.7974 - val_loss: 51.5212\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 42.9481 - val_loss: 40.4127\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 41.5275 - val_loss: 46.9468\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 42.8301 - val_loss: 66.7357\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 44.1126 - val_loss: 387.9267\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 43.3434 - val_loss: 39.1626\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 96.3774 - val_loss: 1683342811678987520.0000\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 121.3519 - val_loss: 14676684624896.0000\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 79.3476 - val_loss: 5200714.3099\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 65.2475 - val_loss: 47457.5617\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 61.9937 - val_loss: 2421.2777\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 58.6526 - val_loss: 1562.5647\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 60.8115 - val_loss: 85.0106\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 59.3217 - val_loss: 89.1357\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 58.0094 - val_loss: 109.0225\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 55.5720 - val_loss: 64.6524\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 56.5322 - val_loss: 56.0554\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 22s 690ms/step - loss: 55.7624 - val_loss: 51.4884\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 53.1789 - val_loss: 49.6709\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 56.9807 - val_loss: 55.3126\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 55.2418 - val_loss: 57.3951\n",
      "Epoch 154/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 22s 691ms/step - loss: 52.6116 - val_loss: 53.5324\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 52.7767 - val_loss: 54.5442\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 49.9940 - val_loss: 47.1934\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 22s 690ms/step - loss: 52.1944 - val_loss: 59.0074\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 22s 690ms/step - loss: 50.1699 - val_loss: 53.4573\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 22s 690ms/step - loss: 48.7486 - val_loss: 56.9240\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 22s 689ms/step - loss: 50.4433 - val_loss: 54.3899\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 22s 690ms/step - loss: 49.4565 - val_loss: 51.6772\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 22s 692ms/step - loss: 49.2253 - val_loss: 51.7621\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 48.2943 - val_loss: 43.6572\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 48.3448 - val_loss: 48.4600\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 49.0457 - val_loss: 46.3964\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 46.7287 - val_loss: 53.6703\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 47.6384 - val_loss: 56.8659\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 44.2464 - val_loss: 46.3511\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 22s 692ms/step - loss: 47.7358 - val_loss: 45.0042\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 48.1851 - val_loss: 44.4109\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 47.1484 - val_loss: 51.1741\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 22s 692ms/step - loss: 45.9355 - val_loss: 48.6974\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 46.7912 - val_loss: 62.7621\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 44.8471 - val_loss: 44.4191\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 45.4491 - val_loss: 50.7898\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 44.1743 - val_loss: 41.2978\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 44.2377 - val_loss: 53.0952\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 22s 692ms/step - loss: 45.0511 - val_loss: 41.1719\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 46.5245 - val_loss: 44.7074\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 46.2752 - val_loss: 45.8674\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 22s 692ms/step - loss: 42.9739 - val_loss: 49.3230\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 43.8751 - val_loss: 50.9440\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 45.7599 - val_loss: 50.1539\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 46.2988 - val_loss: 47.9304\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 46.2112 - val_loss: 50.4410\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 52.7383 - val_loss: 55.2404\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 48.6743 - val_loss: 62.1669\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 45.4204 - val_loss: 55.3642\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 22s 692ms/step - loss: 47.6911 - val_loss: 44.4940\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 46.7135 - val_loss: 56.2160\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 44.4913 - val_loss: 42.3864\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 45.2767 - val_loss: 48.0029\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 49.2629 - val_loss: 44.5732\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 47.5170 - val_loss: 51.5359\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 22s 692ms/step - loss: 47.7273 - val_loss: 53.5473\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 49.2715 - val_loss: 62.0869\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 53.1511 - val_loss: 56.7140\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 52.4334 - val_loss: 51.0111\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 22s 692ms/step - loss: 53.6457 - val_loss: 48.4162\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 48.0624 - val_loss: 48.7900\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-ca8da4d8340a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mannotation_lines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manchors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m     \u001b[0m_main\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-ca8da4d8340a>\u001b[0m in \u001b[0;36m_main\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manchors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannotation_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manchors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannotation_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manchors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'logs/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     model.compile(optimizer='adam', loss={\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sess' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Lambda\n",
    "from keras.models import Model\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
    "from yolo3.model import preprocess_true_boxes, yolo_body, tiny_yolo_body, yolo_loss\n",
    "from yolo3.utils import get_random_data\n",
    "def _main(): \n",
    "    annotation_path = '2007_train.txt'\n",
    "    log_dir = 'logs/000/'\n",
    "    classes_path = 'model_data/voc_classes.txt'\n",
    "    anchors_path = 'model_data/yolo_anchors.txt'\n",
    "    class_names = get_classes(classes_path)\n",
    "    anchors = get_anchors(anchors_path)\n",
    "    input_shape = (416,416) # multiple of 32, hw\n",
    "    model = create_model(input_shape, anchors, len(class_names) )\n",
    "    train(model, annotation_path, input_shape, anchors, len(class_names), log_dir=log_dir)   \n",
    "    sess.close()\n",
    "def train(model, annotation_path, input_shape, anchors, num_classes, log_dir='logs/'):\n",
    "    model.compile(optimizer='adam', loss={\n",
    "        'yolo_loss': lambda y_true, y_pred: y_pred})\n",
    "    logging = TensorBoard(log_dir=log_dir)\n",
    "    checkpoint = ModelCheckpoint(log_dir + \"ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5\",\n",
    "        monitor='val_loss', save_weights_only=True, save_best_only=True, period=1)\n",
    "    batch_size = 2\n",
    "    val_split = 0.1\n",
    "    with open(annotation_path) as f:\n",
    "        lines = f.readlines()\n",
    "    np.random.shuffle(lines)\n",
    "    num_val = int(len(lines)*val_split)\n",
    "    num_train = len(lines) - num_val\n",
    "    print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "    model.fit_generator(data_generator_wrap(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
    "            steps_per_epoch=max(1, num_train//batch_size),\n",
    "            validation_data=data_generator_wrap(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
    "            validation_steps=max(1, num_val//batch_size),\n",
    "            epochs=200,\n",
    "            initial_epoch=0)\n",
    "    model.save_weights(log_dir + 'trained_weights1-1.h5')\n",
    "def get_classes(classes_path):\n",
    "    with open(classes_path) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "    return class_names\n",
    "def get_anchors(anchors_path):\n",
    "    with open(anchors_path) as f:\n",
    "        anchors = f.readline()\n",
    "    anchors = [float(x) for x in anchors.split(',')]\n",
    "    return np.array(anchors).reshape(-1, 2)\n",
    "def create_model(input_shape, anchors, num_classes, load_pretrained=False, freeze_body=False,\n",
    "            weights_path='model_data/yolo_weights.h5'):\n",
    "    K.clear_session() # get a new session\n",
    "    image_input = Input(shape=(None, None, 3))\n",
    "    h, w = input_shape\n",
    "    num_anchors = len(anchors)\n",
    "    y_true = [Input(shape=(h//{0:32, 1:16, 2:8}[l], w//{0:32, 1:16, 2:8}[l], \\\n",
    "        num_anchors//3, num_classes+5)) for l in range(3)]\n",
    "    model_body = yolo_body(image_input, num_anchors//3, num_classes)\n",
    "    print('Create YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
    "    if load_pretrained:\n",
    "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
    "        print('Load weights {}.'.format(weights_path))\n",
    "        if freeze_body:\n",
    "            # Do not freeze 3 output layers.\n",
    "            num = len(model_body.layers)-7\n",
    "            for i in range(num): model_body.layers[i].trainable = False\n",
    "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
    "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
    "        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.5})(\n",
    "        [*model_body.output, *y_true])\n",
    "    model = Model([model_body.input, *y_true], model_loss)\n",
    "    return model\n",
    "def data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
    "    n = len(annotation_lines)\n",
    "    np.random.shuffle(annotation_lines)\n",
    "    i = 0\n",
    "    while True:\n",
    "        image_data = []\n",
    "        box_data = []\n",
    "        for b in range(batch_size):\n",
    "            i %= n\n",
    "            image, box = get_random_data(annotation_lines[i], input_shape, random=True)\n",
    "            image_data.append(image)\n",
    "            box_data.append(box)\n",
    "            i += 1\n",
    "        image_data = np.array(image_data)\n",
    "        box_data = np.array(box_data)\n",
    "        y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes)\n",
    "        yield [image_data, *y_true], np.zeros(batch_size)\n",
    "def data_generator_wrap(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
    "    n = len(annotation_lines)\n",
    "    if n==0 or batch_size<=0: return None\n",
    "    return data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes)\n",
    "if __name__ == '__main__':    \n",
    "    _main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/000/trained_weights1.h5 model, anchors, and classes loaded.\n",
      "(416, 416, 3)\n",
      "Found 1 boxes for img\n",
      "cell 0.40 (305, 75) (416, 201)\n",
      "2.6282370000000004\n",
      "(416, 416, 3)\n",
      "Found 2 boxes for img\n",
      "cell 0.37 (69, 313) (212, 416)\n",
      "cell 0.48 (303, 4) (416, 93)\n",
      "0.14089859999999987\n",
      "(416, 416, 3)\n",
      "Found 2 boxes for img\n",
      "cell 0.35 (69, 312) (212, 416)\n",
      "cell 0.44 (302, 9) (416, 87)\n",
      "0.11178509999999964\n",
      "(416, 416, 3)\n",
      "Found 1 boxes for img\n",
      "cell 0.39 (308, 105) (416, 230)\n",
      "0.10923170000000049\n",
      "(416, 416, 3)\n",
      "Found 1 boxes for img\n",
      "cell 0.45 (320, 311) (407, 416)\n",
      "0.11002590000000012\n",
      "(416, 416, 3)\n",
      "Found 0 boxes for img\n",
      "0.1071049999999989\n",
      "(416, 416, 3)\n",
      "Found 3 boxes for img\n",
      "cell 0.36 (323, 251) (400, 416)\n",
      "cell 0.47 (170, 0) (298, 94)\n",
      "cell 0.48 (0, 0) (159, 84)\n",
      "0.11252599999999902\n",
      "(416, 416, 3)\n",
      "Found 1 boxes for img\n",
      "cell 0.36 (204, 320) (330, 406)\n",
      "0.11090979999999995\n",
      "(416, 416, 3)\n",
      "Found 1 boxes for img\n",
      "cell 0.39 (172, 216) (296, 340)\n",
      "0.1098504000000009\n",
      "(416, 416, 3)\n",
      "Found 0 boxes for img\n",
      "0.1074780999999998\n",
      "(416, 416, 3)\n",
      "Found 2 boxes for img\n",
      "cell 0.39 (90, 144) (190, 268)\n",
      "cell 0.54 (0, 0) (109, 97)\n",
      "0.1311864000000007\n",
      "(416, 416, 3)\n",
      "Found 0 boxes for img\n",
      "0.10594139999999896\n",
      "(416, 416, 3)\n",
      "Found 2 boxes for img\n",
      "cell 0.35 (296, 123) (416, 224)\n",
      "cell 0.37 (296, 288) (416, 395)\n",
      "0.10930560000000256\n",
      "(416, 416, 3)\n",
      "Found 3 boxes for img\n",
      "cell 0.32 (223, 176) (306, 384)\n",
      "cell 0.42 (0, 129) (104, 286)\n",
      "cell 0.62 (0, 286) (98, 377)\n",
      "0.11366569999999854\n",
      "(416, 416, 3)\n",
      "Found 2 boxes for img\n",
      "cell 0.37 (0, 327) (108, 413)\n",
      "cell 0.37 (314, 176) (408, 316)\n",
      "0.11135170000000016\n",
      "(416, 416, 3)\n",
      "Found 0 boxes for img\n",
      "0.10892720000000011\n",
      "(416, 416, 3)\n",
      "Found 1 boxes for img\n",
      "cell 0.34 (5, 6) (99, 91)\n",
      "0.10969509999999971\n",
      "(416, 416, 3)\n",
      "Found 2 boxes for img\n",
      "cell 0.35 (267, 152) (402, 254)\n",
      "cell 0.42 (0, 6) (108, 71)\n",
      "0.14650800000000075\n",
      "(416, 416, 3)\n",
      "Found 2 boxes for img\n",
      "cell 0.46 (155, 309) (260, 416)\n",
      "cell 0.48 (245, 256) (351, 333)\n",
      "0.11323529999999948\n",
      "(416, 416, 3)\n",
      "Found 2 boxes for img\n",
      "cell 0.31 (43, 253) (176, 364)\n",
      "cell 0.48 (167, 218) (315, 323)\n",
      "0.14084319999999906\n",
      "(416, 416, 3)\n",
      "Found 2 boxes for img\n",
      "cell 0.31 (48, 130) (175, 234)\n",
      "cell 0.42 (103, 212) (243, 324)\n",
      "0.11276940000000124\n",
      "(416, 416, 3)\n",
      "Found 0 boxes for img\n",
      "0.10871619999999993\n",
      "(416, 416, 3)\n",
      "Found 2 boxes for img\n",
      "cell 0.30 (7, 211) (152, 325)\n",
      "cell 0.42 (279, 322) (392, 408)\n",
      "0.11252700000000004\n",
      "(416, 416, 3)\n",
      "Found 1 boxes for img\n",
      "cell 0.57 (197, 0) (337, 99)\n",
      "0.11063329999999638\n",
      "(416, 416, 3)\n",
      "Found 0 boxes for img\n",
      "0.10775729999999584\n",
      "(416, 416, 3)\n",
      "Found 2 boxes for img\n",
      "cell 0.39 (131, 250) (216, 416)\n",
      "cell 0.62 (300, 22) (416, 130)\n",
      "0.11144509999999741\n",
      "(416, 416, 3)\n",
      "Found 2 boxes for img\n",
      "cell 0.37 (320, 304) (411, 416)\n",
      "cell 0.40 (90, 6) (205, 75)\n",
      "0.1127544999999941\n",
      "(416, 416, 3)\n",
      "Found 2 boxes for img\n",
      "cell 0.36 (127, 235) (229, 307)\n",
      "cell 0.47 (0, 20) (98, 123)\n",
      "0.111237899999999\n",
      "(416, 416, 3)\n",
      "Found 1 boxes for img\n",
      "cell 0.33 (210, 302) (329, 416)\n",
      "0.10973609999999923\n",
      "(416, 416, 3)\n",
      "Found 1 boxes for img\n",
      "cell 0.32 (30, 166) (133, 262)\n",
      "0.10981780000000185\n",
      "(416, 416, 3)\n",
      "Found 0 boxes for img\n",
      "0.10677280000000167\n",
      "(416, 416, 3)\n",
      "Found 1 boxes for img\n",
      "cell 0.33 (156, 132) (260, 235)\n",
      "0.1074715000000026\n",
      "(416, 416, 3)\n",
      "Found 0 boxes for img\n",
      "0.1066177999999951\n",
      "(416, 416, 3)\n",
      "Found 1 boxes for img\n",
      "cell 0.40 (198, 0) (328, 103)\n",
      "0.10928179999999799\n",
      "(416, 416, 3)\n",
      "Found 0 boxes for img\n",
      "0.10792940000000328\n",
      "(416, 416, 3)\n",
      "Found 0 boxes for img\n",
      "0.10692949999999968\n",
      "(416, 416, 3)\n",
      "Found 3 boxes for img\n",
      "cell 0.30 (96, 184) (194, 289)\n",
      "cell 0.31 (271, 256) (393, 341)\n",
      "cell 0.33 (273, 0) (389, 96)\n",
      "0.11623550000000193\n",
      "(416, 416, 3)\n",
      "Found 1 boxes for img\n",
      "cell 0.34 (0, 191) (116, 277)\n",
      "0.11048449999999832\n",
      "(416, 416, 3)\n",
      "Found 1 boxes for img\n",
      "cell 0.47 (318, 313) (415, 410)\n",
      "0.10949540000000013\n",
      "(416, 416, 3)\n",
      "Found 1 boxes for img\n",
      "cell 0.32 (127, 170) (277, 253)\n",
      "0.11019540000000205\n",
      "(416, 416, 3)\n",
      "Found 0 boxes for img\n",
      "0.10727380000000153\n",
      "(416, 416, 3)\n",
      "Found 1 boxes for img\n",
      "cell 0.31 (106, 3) (305, 83)\n",
      "0.11005349999999936\n",
      "(416, 416, 3)\n",
      "Found 0 boxes for img\n",
      "0.10752019999999618\n",
      "(416, 416, 3)\n",
      "Found 0 boxes for img\n",
      "0.10722950000000253\n",
      "(416, 416, 3)\n",
      "Found 0 boxes for img\n",
      "0.10740100000000297\n",
      "(416, 416, 3)\n",
      "Found 1 boxes for img\n",
      "cell 0.42 (168, 2) (367, 82)\n",
      "0.1101934\n",
      "(416, 416, 3)\n",
      "Found 1 boxes for img\n",
      "cell 0.44 (0, 65) (106, 151)\n",
      "0.10903059999999698\n",
      "(416, 416, 3)\n",
      "Found 0 boxes for img\n",
      "0.10727219999999704\n",
      "(416, 416, 3)\n",
      "Found 0 boxes for img\n",
      "0.10730709999999988\n",
      "(416, 416, 3)\n",
      "Found 1 boxes for img\n",
      "cell 0.44 (201, 115) (350, 179)\n",
      "0.11069540000001155\n",
      "(416, 416, 3)\n",
      "Found 0 boxes for img\n",
      "0.10641210000000001\n",
      "(416, 416, 3)\n",
      "Found 0 boxes for img\n",
      "0.10795350000000781\n",
      "(416, 416, 3)\n",
      "Found 1 boxes for img\n",
      "cell 0.38 (0, 174) (141, 248)\n",
      "0.12354410000000371\n",
      "(416, 416, 3)\n",
      "Found 0 boxes for img\n",
      "0.10743999999999687\n",
      "(416, 416, 3)\n",
      "Found 0 boxes for img\n",
      "0.1070806000000033\n",
      "(416, 416, 3)\n",
      "Found 1 boxes for img\n",
      "cell 0.37 (92, 331) (201, 414)\n",
      "0.10890889999998876\n",
      "(416, 416, 3)\n",
      "Found 1 boxes for img\n",
      "cell 0.37 (93, 332) (201, 414)\n",
      "0.10938619999998878\n",
      "(416, 416, 3)\n",
      "Found 1 boxes for img\n",
      "cell 0.47 (93, 289) (188, 416)\n",
      "0.11014109999999278\n",
      "(416, 416, 3)\n",
      "Found 0 boxes for img\n",
      "0.10677450000000022\n",
      "(416, 416, 3)\n",
      "Found 0 boxes for img\n",
      "0.10762990000000627\n",
      "(416, 416, 3)\n",
      "Found 0 boxes for img\n",
      "0.10557489999999348\n",
      "(416, 416, 3)\n",
      "Found 0 boxes for img\n",
      "0.10461510000000374\n",
      "(416, 416, 3)\n",
      "Found 1 boxes for img\n",
      "cell 0.33 (215, 172) (325, 302)\n",
      "0.10885129999999776\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-18fb9e6c594d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[0mr_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myolo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetect_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m         \u001b[0mr_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m     \u001b[1;31m#end1=timer()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Softwares\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mshow\u001b[1;34m(self, title, command)\u001b[0m\n\u001b[0;32m   2130\u001b[0m         \"\"\"\n\u001b[0;32m   2131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2132\u001b[1;33m         \u001b[0m_show\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcommand\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2134\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Softwares\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36m_show\u001b[1;34m(image, **options)\u001b[0m\n\u001b[0;32m   3042\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_show\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3043\u001b[0m     \u001b[1;31m# override me, as necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3044\u001b[1;33m     \u001b[0m_showxv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Softwares\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36m_showxv\u001b[1;34m(image, title, **options)\u001b[0m\n\u001b[0;32m   3048\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImageShow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3049\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3050\u001b[1;33m     \u001b[0mImageShow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Softwares\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\PIL\\ImageShow.py\u001b[0m in \u001b[0;36mshow\u001b[1;34m(image, title, **options)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \"\"\"\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mviewer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_viewers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mviewer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Softwares\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\PIL\\ImageShow.py\u001b[0m in \u001b[0;36mshow\u001b[1;34m(self, image, **options)\u001b[0m\n\u001b[0;32m     71\u001b[0m                 \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;31m# hook methods\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Softwares\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\PIL\\ImageShow.py\u001b[0m in \u001b[0;36mshow_image\u001b[1;34m(self, image, **options)\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mshow_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[1;34m\"\"\"Display given image\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mshow_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Softwares\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\PIL\\ImageShow.py\u001b[0m in \u001b[0;36mshow_file\u001b[1;34m(self, file, **options)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mshow_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[1;34m\"\"\"Display given file\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Class definition of YOLO_v3 style detection model on image and video\n",
    "\"\"\"\n",
    "import colorsys\n",
    "import os\n",
    "import sys \n",
    "from timeit import default_timer as timer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.layers import Input\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "from yolo3.model import yolo_eval, yolo_body, tiny_yolo_body\n",
    "from yolo3.utils import letterbox_image\n",
    "import os\n",
    "from keras.utils import multi_gpu_model\n",
    "class YOLO(object):\n",
    "    _defaults = {\n",
    "        \"model_path\": 'logs/000/trained_weights1.h5', ##训练好的模型的路径\n",
    "        \"anchors_path\": 'model_data/yolo_anchors.txt',\n",
    "        \"classes_path\": 'model_data/voc_classes.txt',\n",
    "        \"score\" : 0.3,\n",
    "        \"iou\" : 0.45,\n",
    "        \"model_image_size\" : (416, 416),\n",
    "        \"gpu_num\" : 0\n",
    "    }\n",
    "    @classmethod\n",
    "    def get_defaults(cls, n):\n",
    "        if n in cls._defaults:\n",
    "            return cls._defaults[n]\n",
    "        else:\n",
    "            return \"Unrecognized attribute name '\" + n + \"'\"\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(self._defaults) # set up default values\n",
    "        self.__dict__.update(kwargs) # and update with user overrides\n",
    "        self.class_names = self._get_class()\n",
    "        self.anchors = self._get_anchors()\n",
    "        self.sess = K.get_session()\n",
    "        self.boxes, self.scores, self.classes = self.generate()\n",
    "    def _get_class(self):\n",
    "        classes_path = os.path.expanduser(self.classes_path)\n",
    "        with open(classes_path) as f:\n",
    "            class_names = f.readlines()\n",
    "        class_names = [c.strip() for c in class_names]\n",
    "        return class_names\n",
    "    def _get_anchors(self):\n",
    "        anchors_path = os.path.expanduser(self.anchors_path)\n",
    "        with open(anchors_path) as f:\n",
    "            anchors = f.readline()\n",
    "        anchors = [float(x) for x in anchors.split(',')]\n",
    "        return np.array(anchors).reshape(-1, 2)\n",
    "    def generate(self):\n",
    "        model_path = os.path.expanduser(self.model_path)\n",
    "        assert model_path.endswith('.h5'), 'Keras model or weights must be a .h5 file.'\n",
    "        # Load model, or construct model and load weights.\n",
    "        num_anchors = len(self.anchors)\n",
    "        num_classes = len(self.class_names)\n",
    "        is_tiny_version = num_anchors==6 # default setting\n",
    "        try:\n",
    "            self.yolo_model = load_model(model_path, compile=False)\n",
    "        except:\n",
    "            self.yolo_model = tiny_yolo_body(Input(shape=(None,None,3)), num_anchors//2, num_classes) \\\n",
    "                if is_tiny_version else yolo_body(Input(shape=(None,None,3)), num_anchors//3, num_classes)\n",
    "            self.yolo_model.load_weights(self.model_path) # make sure model, anchors and classes match\n",
    "        else:\n",
    "            assert self.yolo_model.layers[-1].output_shape[-1] == \\\n",
    "                num_anchors/len(self.yolo_model.output) * (num_classes + 5), \\\n",
    "                'Mismatch between model and given anchor and class sizes'\n",
    "        print('{} model, anchors, and classes loaded.'.format(model_path))\n",
    "        # Generate colors for drawing bounding boxes.\n",
    "        hsv_tuples = [(x / len(self.class_names), 1., 1.)\n",
    "                      for x in range(len(self.class_names))]\n",
    "        self.colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "        self.colors = list(\n",
    "            map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)),\n",
    "                self.colors))\n",
    "        np.random.seed(10101)  # Fixed seed for consistent colors across runs.\n",
    "        np.random.shuffle(self.colors)  # Shuffle colors to decorrelate adjacent classes.\n",
    "        np.random.seed(None)  # Reset seed to default.\n",
    "        # Generate output tensor targets for filtered bounding boxes.\n",
    "        self.input_image_shape = K.placeholder(shape=(2, ))\n",
    "        if self.gpu_num>=2:\n",
    "            self.yolo_model = multi_gpu_model(self.yolo_model, gpus=self.gpu_num)\n",
    "        boxes, scores, classes = yolo_eval(self.yolo_model.output, self.anchors,\n",
    "                len(self.class_names), self.input_image_shape,\n",
    "                score_threshold=self.score, iou_threshold=self.iou)\n",
    "        return boxes, scores, classes\n",
    "    def detect_image(self, image):\n",
    "        start = timer()\n",
    "        if self.model_image_size != (None, None):\n",
    "            assert self.model_image_size[0]%32 == 0, 'Multiples of 32 required'\n",
    "            assert self.model_image_size[1]%32 == 0, 'Multiples of 32 required'\n",
    "            boxed_image = letterbox_image(image, tuple(reversed(self.model_image_size)))\n",
    "        else:\n",
    "            new_image_size = (image.width - (image.width % 32),\n",
    "                              image.height - (image.height % 32))\n",
    "            boxed_image = letterbox_image(image, new_image_size)\n",
    "        image_data = np.array(boxed_image, dtype='float32')\n",
    "        print(image_data.shape)\n",
    "        image_data /= 255.\n",
    "        image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n",
    "        out_boxes, out_scores, out_classes = self.sess.run(\n",
    "            [self.boxes, self.scores, self.classes],\n",
    "            feed_dict={\n",
    "                self.yolo_model.input: image_data,\n",
    "                self.input_image_shape: [image.size[1], image.size[0]],\n",
    "                K.learning_phase(): 0\n",
    "            })\n",
    "        print('Found {} boxes for {}'.format(len(out_boxes), 'img'))\n",
    "        font = ImageFont.truetype(font='font/FiraMono-Medium.otf',\n",
    "                    size=np.floor(3e-2 * image.size[1] + 0.5).astype('int32'))\n",
    "        thickness = (image.size[0] + image.size[1]) // 300\n",
    "        for i, c in reversed(list(enumerate(out_classes))):\n",
    "            predicted_class = self.class_names[c]\n",
    "            box = out_boxes[i]\n",
    "            score = out_scores[i]\n",
    "            label = '{} {:.2f}'.format(predicted_class, score)\n",
    "            draw = ImageDraw.Draw(image)\n",
    "            label_size = draw.textsize(label, font)\n",
    "            top, left, bottom, right = box\n",
    "            top = max(0, np.floor(top + 0.5).astype('int32'))\n",
    "            left = max(0, np.floor(left + 0.5).astype('int32'))\n",
    "            bottom = min(image.size[1], np.floor(bottom + 0.5).astype('int32'))\n",
    "            right = min(image.size[0], np.floor(right + 0.5).astype('int32'))\n",
    "            print(label, (left, top), (right, bottom))\n",
    "            image2 = []\n",
    "            cellname = timer()\n",
    "            cellpath = './result/'\n",
    "            image2 = image.crop((left,top,right,bottom))\n",
    "            image2.save(cellpath+str(timer())+'.jpg')\n",
    "            #new_f=open(\"/home/shan/xws/pro/keras-yolo3/detection-results/\"+tmp_file.replace(\".jpg\", \".txt\"), \"a\")\n",
    "            new_f.write(\"%s %s %s %s %s\\n\" %  (label, left, top, right, bottom))\n",
    "            if top - label_size[1] >= 0:\n",
    "                text_origin = np.array([left, top - label_size[1]])\n",
    "            else:\n",
    "                text_origin = np.array([left, top + 1])\n",
    "            # My kingdom for a good redistributable image drawing library.\n",
    "            for i in range(thickness):\n",
    "                draw.rectangle(\n",
    "                    [left + i, top + i, right - i, bottom - i],\n",
    "                    outline=self.colors[c])\n",
    "            draw.rectangle(\n",
    "                [tuple(text_origin), tuple(text_origin + label_size)],\n",
    "                fill=self.colors[c])\n",
    "            draw.text(text_origin, label, fill=(0, 0, 0), font=font)\n",
    "            del draw\n",
    "        end = timer()\n",
    "        print(end - start)\n",
    "        return image\n",
    "    def close_session(self):\n",
    "        self.sess.close()\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    # yolo=YOLO()\n",
    "    # path = '1.jpg'\n",
    "    # try:\n",
    "    #     image = Image.open(path)\n",
    "    # except:\n",
    "    #     print('Open Error! Try again!')\n",
    "    # else:\n",
    "    #     r_image = yolo.detect_image(image)\n",
    "    #     r_image.show()\n",
    "    # yolo.close_session()\n",
    "    #strat1=timer()\n",
    "    dirname='./test/'  ##该目录为测试照片的存储路径，每次测试照片的数量可以自己设定\n",
    "    path=os.path.join(dirname)\n",
    "    pic_list=os.listdir(path) \n",
    "    count=0\n",
    "    yolo=YOLO()\n",
    "    for filename in pic_list:\n",
    "        tmp_file=pic_list[count]\n",
    "        new_f=open('./result'+tmp_file.replace(\".jpg\", \".txt\"), \"a\")  #预测坐标生成txt文件保存的路径\n",
    "        abs_path=path+pic_list[count]\n",
    "        image = Image.open(abs_path)\n",
    "        r_image = yolo.detect_image(image)\n",
    "        count=count+1\n",
    "        r_image.show()\n",
    "    #end1=timer()\n",
    "    print(count)\n",
    "    yolo.close_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
